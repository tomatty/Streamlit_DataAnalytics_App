"""
Word frequency analysis module with Japanese support.
"""
import os
import pandas as pd
import streamlit as st
import plotly.express as px
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

try:
    from janome.tokenizer import Tokenizer
    JANOME_AVAILABLE = True
except ImportError:
    JANOME_AVAILABLE = False

_JP_FONT_CANDIDATES = [
    "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W4.ttc",
    "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒè§’ã‚´ã‚·ãƒƒã‚¯ W3.ttc",
    "/System/Library/Fonts/ãƒ’ãƒ©ã‚®ãƒæ˜æœ ProN.ttc",
    "/System/Library/Fonts/Hiragino Sans GB.ttc",
]


def _find_jp_font() -> str | None:
    for path in _JP_FONT_CANDIDATES:
        if os.path.exists(path):
            return path
    return None


def _render_wordcloud_matplotlib(wc: WordCloud, font_path: str | None) -> plt.Figure:
    """
    Re-render WordCloud layout using matplotlib's FreeType renderer.

    WordCloud uses PIL internally, which cannot always access Japanese glyphs
    from macOS .ttc files. This function takes the already-computed layout
    (word positions, sizes, orientations) and draws each word with matplotlib,
    which handles Japanese fonts via FreeType correctly.
    """
    WC_WIDTH = wc.width
    WC_HEIGHT = wc.height

    font_props = fm.FontProperties(fname=font_path) if font_path else None
    if font_path:
        fm.fontManager.addfont(font_path)

    fig, ax = plt.subplots(figsize=(10, 5))
    fig.patch.set_facecolor(wc.background_color)
    ax.set_facecolor(wc.background_color)
    # Match PIL coordinate system: origin top-left, y increases downward
    ax.set_xlim(0, WC_WIDTH)
    ax.set_ylim(WC_HEIGHT, 0)
    ax.axis("off")
    plt.tight_layout(pad=0)

    for (word, _), font_size, (x, y), orientation, color in wc.layout_:
        rot = 90 if orientation else 0
        ax.text(
            x, y, word,
            fontsize=font_size * 0.75,
            fontproperties=font_props,
            color=color,
            rotation=rot,
            ha="left",
            va="top",
        )

    return fig


def show_word_frequency_analysis(df: pd.DataFrame):
    """Display word frequency analysis interface."""
    st.subheader("ğŸ“ å˜èªé »åº¦åˆ†æ")

    text_cols = df.select_dtypes(include=["object"]).columns.tolist()

    if not text_cols:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    col1, col2 = st.columns(2)
    with col1:
        text_col = st.selectbox("ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã‚’é¸æŠ", text_cols)
    with col2:
        language = st.selectbox("è¨€èª", ["æ—¥æœ¬èª", "è‹±èª"])

    if language == "æ—¥æœ¬èª" and not JANOME_AVAILABLE:
        st.error("JanomeãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install janome`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    max_words = st.slider("åˆ†æã™ã‚‹å˜èªæ•°ï¼ˆãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šé™ï¼‰", min_value=10, max_value=100, value=50)

    if st.button("å˜èªé »åº¦åˆ†æã‚’å®Ÿè¡Œ", type="primary"):
        try:
            texts = df[text_col].dropna()

            if len(texts) == 0:
                st.error("æœ‰åŠ¹ãªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return

            # Tokenize
            if language == "æ—¥æœ¬èª":
                tokenizer = Tokenizer()
                words = []
                for text in texts:
                    tokens = tokenizer.tokenize(str(text))
                    words.extend([
                        token.base_form for token in tokens
                        if token.part_of_speech.split(",")[0] in ["åè©", "å‹•è©", "å½¢å®¹è©"]
                    ])
            else:
                words = []
                for text in texts:
                    words.extend(str(text).lower().split())

            if len(words) == 0:
                st.error("æœ‰åŠ¹ãªå˜èªãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

            word_counts = Counter(words)
            top_words = word_counts.most_common(max_words)

            st.success(f"å˜èªé »åº¦åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼ˆç·å˜èªæ•°: {len(words)}ï¼‰")

            # Frequency table
            st.markdown("### é »å‡ºå˜èªãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            freq_df = pd.DataFrame(top_words, columns=["å˜èª", "å‡ºç¾å›æ•°"])
            freq_df["é †ä½"] = range(1, len(freq_df) + 1)
            freq_df = freq_df[["é †ä½", "å˜èª", "å‡ºç¾å›æ•°"]]
            st.dataframe(freq_df, use_container_width=True)

            # Horizontal bar chart with display-count control
            st.markdown("### å˜èªé »åº¦ã‚°ãƒ©ãƒ•")
            chart_n = st.slider(
                "ã‚°ãƒ©ãƒ•è¡¨ç¤ºæ•°",
                min_value=5,
                max_value=min(max_words, len(freq_df)),
                value=min(20, len(freq_df)),
                key="chart_n_slider",
            )
            chart_df = freq_df.head(chart_n).sort_values("å‡ºç¾å›æ•°", ascending=True)
            fig = px.bar(
                chart_df,
                x="å‡ºç¾å›æ•°",
                y="å˜èª",
                orientation="h",
                title=f"Top {chart_n} å˜èª",
            )
            fig.update_layout(yaxis={"tickfont": {"size": 11}})
            st.plotly_chart(fig, use_container_width=True)

            # Word cloud
            st.markdown("### ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰")
            try:
                font_path = _find_jp_font() if language == "æ—¥æœ¬èª" else None
                wc = WordCloud(
                    width=800,
                    height=400,
                    background_color="white",
                    font_path=font_path,
                    max_words=max_words,
                ).generate_from_frequencies(dict(word_counts))

                if language == "æ—¥æœ¬èª" and font_path:
                    # matplotlib rendering to avoid PIL glyph issue with .ttc fonts
                    fig_wc = _render_wordcloud_matplotlib(wc, font_path)
                else:
                    fig_wc, ax = plt.subplots(figsize=(10, 5))
                    ax.imshow(wc, interpolation="bilinear")
                    ax.axis("off")

                st.pyplot(fig_wc)
                plt.close(fig_wc)
            except Exception as e:
                st.warning(f"ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

            # Download
            csv = freq_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="å˜èªé »åº¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="word_frequency.csv",
                mime="text/csv",
            )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
