"""
Decision Tree analysis module.
Supports both classification and regression tasks.
"""
import matplotlib
import matplotlib.font_manager as _fm
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    mean_absolute_error,
    mean_squared_error,
    r2_score,
)
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_text, plot_tree

# Search for an available Japanese font (installed via packages.txt or japanize-matplotlib)
_JP_FONT_CANDIDATES = [
    "Noto Sans CJK JP",
    "Noto Sans JP",
    "IPAexGothic",
    "IPAGothic",
    "TakaoGothic",
    "VL Gothic",
    "Hiragino Sans",
    "Yu Gothic",
]
try:
    _fm._load_fontmanager(try_read_cache=False)
except Exception:
    pass
_available = {f.name for f in _fm.fontManager.ttflist}
for _candidate in _JP_FONT_CANDIDATES:
    if _candidate in _available:
        matplotlib.rcParams["font.family"] = _candidate
        break

_SS = "dt_results"  # session_state key


def show_decision_tree(df: pd.DataFrame):
    """Display Decision Tree analysis interface."""
    st.subheader("ğŸŒ³ æ±ºå®šæœ¨åˆ†æ")

    with st.expander("ğŸ“– ä¸€èˆ¬çš„ãªåˆ†ææ‰‹é †", expanded=False):
        st.markdown(
            """
### æ±ºå®šæœ¨åˆ†æã®åŸºæœ¬çš„ãªæµã‚Œ

**1. ç›®çš„ã®æ˜ç¢ºåŒ–**
- åˆ†é¡å•é¡Œ: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’äºˆæ¸¬ï¼ˆä¾‹: é¡§å®¢ãŒè³¼å…¥ã™ã‚‹ã‹/ã—ãªã„ã‹ï¼‰
- å›å¸°å•é¡Œ: æ•°å€¤ã‚’äºˆæ¸¬ï¼ˆä¾‹: å£²ä¸Šé‡‘é¡ã®äºˆæ¸¬ï¼‰
- ãƒ«ãƒ¼ãƒ«æŠ½å‡º: if-thenå½¢å¼ã®åˆ¤æ–­åŸºæº–ã‚’å¯è¦–åŒ–
- ç‰¹å¾´é‡é‡è¦åº¦ã®æŠŠæ¡: ã©ã®å¤‰æ•°ãŒäºˆæ¸¬ã«é‡è¦ã‹

**2. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**
- **ãƒ‡ãƒ¼ã‚¿å½¢å¼**:
  ```
  | ã‚µãƒ³ãƒ—ãƒ«ID | ç‰¹å¾´é‡1 | ç‰¹å¾´é‡2 | ç‰¹å¾´é‡3 | ç›®çš„å¤‰æ•° |
  |-----------|--------|--------|--------|---------|
  | 1         | 25     | 50000  | 3      | è³¼å…¥    |
  | 2         | 35     | 75000  | 5      | éè³¼å…¥  |
  ```
- ç‰¹å¾´é‡ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰: äºˆæ¸¬ã«ä½¿ã†å¤‰æ•°
- ç›®çš„å¤‰æ•°: äºˆæ¸¬ã—ãŸã„å¤‰æ•°
- **ã‚«ãƒ†ã‚´ãƒªãƒ¼å¤‰æ•°ã®æ‰±ã„**:
  - **ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆæ¨å¥¨ï¼‰**: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ•´æ•°ã«å¤‰æ›
    - ä¾‹: æ€§åˆ¥ï¼ˆç”·/å¥³ï¼‰â†’ 0/1ã€åœ°åŸŸï¼ˆæ±äº¬/å¤§é˜ª/åå¤å±‹ï¼‰â†’ 0/1/2
    - æ±ºå®šæœ¨ã¯åˆ†å²æ¡ä»¶ã¨ã—ã¦ä½¿ã†ã ã‘ãªã®ã§ã€é †åºã¯é–¢ä¿‚ãªã„
    - ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ä¸è¦ï¼ˆæœ¨ãŒæ·±ããªã‚ŠéåŠ¹ç‡ï¼‰
  - ç›®çš„å¤‰æ•°ãŒã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å ´åˆã¯è‡ªå‹•çš„ã«ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

**3. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š**
- **max_depthï¼ˆæœ€å¤§æ·±ã•ï¼‰**: æœ¨ã®æ·±ã•ã®ä¸Šé™ï¼ˆ3-10ç¨‹åº¦ï¼‰
  - æ·±ã„ã»ã©è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ãŒã€éå­¦ç¿’ã®ãƒªã‚¹ã‚¯
- **min_samples_split**: åˆ†å‰²ã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ2-20ç¨‹åº¦ï¼‰
  - å¤§ãã„ã»ã©ã‚·ãƒ³ãƒ—ãƒ«ãªæœ¨ã«ãªã‚‹

**4. ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡**
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ï¼ˆé€šå¸¸80:20ï¼‰
- **åˆ†é¡ã‚¿ã‚¹ã‚¯**: æ­£è§£ç‡ã€æ··åŒè¡Œåˆ—ã€é©åˆç‡ãƒ»å†ç¾ç‡
- **å›å¸°ã‚¿ã‚¹ã‚¯**: RÂ²ã€RMSEã€MAE

**5. çµæœã®è§£é‡ˆ**
- æ¨¹å½¢å›³: ã©ã®ã‚ˆã†ãªåˆ¤æ–­åŸºæº–ã§äºˆæ¸¬ã—ã¦ã„ã‚‹ã‹
- ç‰¹å¾´é‡é‡è¦åº¦: ã©ã®å¤‰æ•°ãŒé‡è¦ã‹
- ãƒ«ãƒ¼ãƒ«æŠ½å‡º: ãƒ“ã‚¸ãƒã‚¹ã§æ´»ç”¨ã§ãã‚‹åˆ¤æ–­åŸºæº–

**6. æ³¨æ„ç‚¹**
- éå­¦ç¿’ã—ã‚„ã™ã„ï¼ˆæ·±ã™ãã‚‹æœ¨ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«é©åˆï¼‰
- max_depthã‚„min_samples_splitã§åˆ¶å¾¡
- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ï¼ˆRandom Forestã€LightGBMï¼‰ã§ã•ã‚‰ã«ç²¾åº¦å‘ä¸Šå¯èƒ½
            """
        )

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    all_cols = df.columns.tolist()

    if len(all_cols) < 2:
        st.warning("æ±ºå®šæœ¨åˆ†æã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    col1, col2 = st.columns(2)
    with col1:
        target_col = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰", all_cols, key="dt_target")
    with col2:
        task_type = st.radio(
            "ã‚¿ã‚¹ã‚¯ç¨®åˆ¥",
            ["åˆ†é¡ï¼ˆClassificationï¼‰", "å›å¸°ï¼ˆRegressionï¼‰"],
            key="dt_task",
            horizontal=True,
        )

    feature_cols = st.multiselect(
        "èª¬æ˜å¤‰æ•°ï¼ˆç‰¹å¾´é‡ï¼‰",
        [c for c in numeric_cols if c != target_col],
        default=[c for c in numeric_cols if c != target_col][:min(5, len(numeric_cols))],
        key="dt_features",
    )

    if len(feature_cols) < 1:
        st.info("å°‘ãªãã¨ã‚‚1ã¤ã®èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    col3, col4, col5 = st.columns(3)
    with col3:
        max_depth = st.slider("æœ€å¤§æ·±ã•ï¼ˆmax_depthï¼‰", min_value=1, max_value=10, value=4, key="dt_depth")
    with col4:
        min_samples_split = st.slider("åˆ†å‰²æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°", min_value=2, max_value=20, value=5, key="dt_mss")
    with col5:
        test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ", min_value=0.1, max_value=0.4, value=0.2, step=0.05, key="dt_test")

    if st.button("æ±ºå®šæœ¨åˆ†æã‚’å®Ÿè¡Œ", type="primary", key="dt_run"):
        try:
            data_subset = df[feature_cols + [target_col]].dropna()

            if len(data_subset) < 10:
                st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½10è¡Œå¿…è¦ï¼‰ã€‚")
                return

            X = data_subset[feature_cols]
            y_raw = data_subset[target_col]
            is_regression = task_type.startswith("å›å¸°")

            le = None
            if is_regression:
                y = y_raw.astype(float)
                model = DecisionTreeRegressor(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42,
                )
            else:
                le = LabelEncoder()
                y = le.fit_transform(y_raw.astype(str))
                model = DecisionTreeClassifier(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42,
                )

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            if is_regression:
                n_cv = min(5, len(y) // 2)
                cv_scores = cross_val_score(model, X, y, cv=n_cv, scoring="r2") if n_cv >= 2 else None
                metrics = {
                    "r2": r2_score(y_test, y_pred),
                    "rmse": float(np.sqrt(mean_squared_error(y_test, y_pred))),
                    "mae": float(mean_absolute_error(y_test, y_pred)),
                    "cv_mean": float(cv_scores.mean()) if cv_scores is not None else None,
                    "cv_std": float(cv_scores.std()) if cv_scores is not None else None,
                }
            else:
                min_class_count = int(np.bincount(y).min())
                n_cv = min(5, min_class_count)
                cv_scores = cross_val_score(model, X, y, cv=n_cv, scoring="accuracy") if n_cv >= 2 else None
                metrics = {
                    "acc": float(accuracy_score(y_test, y_pred)),
                    "cv_mean": float(cv_scores.mean()) if cv_scores is not None else None,
                    "cv_std": float(cv_scores.std()) if cv_scores is not None else None,
                    "depth": int(model.get_depth()),
                }

            # Save to session_state
            st.session_state[_SS] = {
                "model": model,
                "feature_cols": feature_cols,
                "is_regression": is_regression,
                "max_depth": max_depth,
                "le": le,
                "y_test": y_test,
                "y_pred": y_pred,
                "X": X,
                "metrics": metrics,
            }

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return

    # ---- Render results from session_state ----
    if _SS not in st.session_state:
        return

    res = st.session_state[_SS]
    model = res["model"]
    feature_cols = res["feature_cols"]
    is_regression = res["is_regression"]
    max_depth = res["max_depth"]
    le = res["le"]
    y_test = res["y_test"]
    y_pred = res["y_pred"]
    X = res["X"]
    metrics = res["metrics"]

    st.success("æ±ºå®šæœ¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    # --- Metrics ---
    st.markdown("### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™")

    if is_regression:
        r2, rmse, mae = metrics["r2"], metrics["rmse"], metrics["mae"]
        m_cols = st.columns(4)
        with m_cols[0]:
            with st.container(border=True):
                st.metric("RÂ²ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{r2:.4f}")
        with m_cols[1]:
            with st.container(border=True):
                st.metric("RMSE", f"{rmse:.4f}")
        with m_cols[2]:
            with st.container(border=True):
                st.metric("MAE", f"{mae:.4f}")
        with m_cols[3]:
            with st.container(border=True):
                cv_val = f"{metrics['cv_mean']:.4f}" if metrics["cv_mean"] is not None else "N/A"
                st.metric("CV RÂ²ï¼ˆå¹³å‡ï¼‰", cv_val)

        if metrics["cv_mean"] is None:
            st.warning("ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚äº¤å·®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        with st.expander("ğŸ“– å›å¸°æŒ‡æ¨™ã®è§£é‡ˆ"):
            cv_detail = f"CV RÂ²={metrics['cv_mean']:.4f}" if metrics["cv_mean"] is not None else "CV: ã‚¹ã‚­ãƒƒãƒ—"
            st.markdown(
                f"""
**RÂ²**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ±ºå®šä¿‚æ•°ã€‚1ã«è¿‘ã„ã»ã©è‰¯ã„äºˆæ¸¬ã€‚

**RMSE / MAE**: äºˆæ¸¬èª¤å·®ã€‚ç›®çš„å¤‰æ•°ã¨åŒã˜å˜ä½ã§è§£é‡ˆã§ãã‚‹ã€‚

**CV RÂ²**: äº¤å·®æ¤œè¨¼ã®å¹³å‡RÂ²ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: RÂ²={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, {cv_detail}
                """
            )
    else:
        acc = metrics["acc"]
        m_cols = st.columns(3)
        with m_cols[0]:
            with st.container(border=True):
                st.metric("æ­£è§£ç‡ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{acc:.4f}")
        with m_cols[1]:
            with st.container(border=True):
                cv_val = f"{metrics['cv_mean']:.4f}" if metrics["cv_mean"] is not None else "N/A"
                st.metric("CV æ­£è§£ç‡ï¼ˆå¹³å‡ï¼‰", cv_val)
        with m_cols[2]:
            with st.container(border=True):
                st.metric("æœ¨ã®æ·±ã•", f"{metrics['depth']}")

        if metrics["cv_mean"] is None:
            st.warning("ä¸€éƒ¨ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚äº¤å·®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        st.markdown("#### åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
        report_dict = classification_report(
            y_test, y_pred,
            target_names=le.classes_.astype(str),
            output_dict=True,
        )
        report_df = pd.DataFrame(report_dict).T
        st.dataframe(
            report_df.style.format("{:.3f}", subset=["precision", "recall", "f1-score"]),
            width="stretch",
        )

        st.markdown("#### æ··åŒè¡Œåˆ—")
        cm = confusion_matrix(y_test, y_pred)
        fig_cm = px.imshow(
            cm,
            labels=dict(x="äºˆæ¸¬ã‚¯ãƒ©ã‚¹", y="å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹", color="ä»¶æ•°"),
            x=le.classes_.astype(str),
            y=le.classes_.astype(str),
            text_auto=True,
            color_continuous_scale="Blues",
        )
        fig_cm.update_layout(title="æ··åŒè¡Œåˆ—")
        st.plotly_chart(fig_cm, width="stretch")

        with st.expander("ğŸ“– åˆ†é¡æŒ‡æ¨™ã®è§£é‡ˆ"):
            st.markdown(
                f"""
**æ­£è§£ç‡ï¼ˆAccuracyï¼‰**: å…¨äºˆæ¸¬ã®ã†ã¡æ­£ã—ãåˆ†é¡ã•ã‚ŒãŸå‰²åˆã€‚

**Precision / Recall / F1**: ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ»èª¿å’Œå¹³å‡ã€‚

**CV æ­£è§£ç‡**: äº¤å·®æ¤œè¨¼ã®å¹³å‡æ­£è§£ç‡ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: æ­£è§£ç‡={acc:.4f}{f", CV={metrics['cv_mean']:.4f}Â±{metrics['cv_std']:.4f}" if metrics['cv_mean'] is not None else ", CV: ã‚¹ã‚­ãƒƒãƒ—"}
                """
            )

    # --- Feature Importance ---
    st.markdown("### ç‰¹å¾´é‡ã®é‡è¦åº¦")
    importance_df = pd.DataFrame({
        "ç‰¹å¾´é‡": feature_cols,
        "é‡è¦åº¦": model.feature_importances_,
    }).sort_values("é‡è¦åº¦", ascending=False)

    fig_imp = px.bar(
        importance_df,
        x="é‡è¦åº¦",
        y="ç‰¹å¾´é‡",
        orientation="h",
        title="ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆGiniä¸ç´”åº¦ãƒ™ãƒ¼ã‚¹ï¼‰",
        color="é‡è¦åº¦",
        color_continuous_scale="Blues",
    )
    fig_imp.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
    st.plotly_chart(fig_imp, width="stretch")

    # --- Tree visualization ---
    st.markdown("### æœ¨ã®æ§‹é€ ")
    tab_plot, tab_text = st.tabs(["æ¨¹å½¢å›³", "ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º"])

    with tab_plot:
        col_depth, col_prop = st.columns([2, 1])
        with col_depth:
            display_depth = st.slider(
                "è¡¨ç¤ºã™ã‚‹æ·±ã•",
                min_value=1,
                max_value=min(max_depth, 6),
                value=min(3, max_depth),
                key="dt_display_depth",
            )
        with col_prop:
            show_proportion = st.checkbox(
                "å‰²åˆã§è¡¨ç¤º",
                value=False,
                key="dt_show_proportion",
                help="ã‚µãƒ³ãƒ—ãƒ«æ•°ã®ä»£ã‚ã‚Šã«å…¨ä½“ã«å¯¾ã™ã‚‹å‰²åˆï¼ˆç¢ºç‡ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™",
            )

        class_names = le.classes_.astype(str).tolist() if not is_regression else None
        actual_depth = model.get_depth()
        # Cap visible leaves to avoid over-expanding the figure
        visible_leaves = min(2 ** display_depth, model.get_n_leaves())
        fig_width = max(10, min(visible_leaves * 2.5, 48))
        fig_height = max(5, display_depth * 3.2)
        fontsize = max(9, 13 - display_depth)
        fig_tree, ax = plt.subplots(figsize=(fig_width, fig_height))
        plot_tree(
            model,
            max_depth=display_depth,
            feature_names=feature_cols,
            class_names=class_names,
            filled=True,
            rounded=True,
            fontsize=fontsize,
            impurity=True,
            proportion=show_proportion,
            precision=3,
            ax=ax,
        )
        ax.set_title(
            f"æ±ºå®šæœ¨ï¼ˆè¡¨ç¤ºæ·±ã•: {display_depth} / å®Ÿéš›ã®æ·±ã•: {actual_depth}ï¼‰",
            fontsize=12,
        )
        st.pyplot(fig_tree, width="stretch")
        plt.close(fig_tree)

        with st.expander("ğŸ“– æ¨¹å½¢å›³ã®è¦‹æ–¹"):
            if show_proportion:
                st.markdown(
                    """
**å„ãƒãƒ¼ãƒ‰ã®è¡¨ç¤ºå†…å®¹ï¼š**
- **åˆ†å‰²æ¡ä»¶**: ç‰¹å¾´é‡ <= é–¾å€¤ï¼ˆå†…éƒ¨ãƒãƒ¼ãƒ‰ã®ã¿ï¼‰
- **gini/entropy**: ä¸ç´”åº¦ï¼ˆ0ã«è¿‘ã„ã»ã©ç´”ç²‹ï¼‰
- **samples**: å…¨ä½“ã«å¯¾ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®å‰²åˆï¼ˆ0.0ã€œ1.0ï¼‰
- **value**: å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«å‰²åˆï¼ˆåˆ†é¡ï¼‰ã¾ãŸã¯äºˆæ¸¬å€¤ï¼ˆå›å¸°ï¼‰
- **class**: æœ€ã‚‚å¤šã„ã‚¯ãƒ©ã‚¹ï¼ˆåˆ†é¡ã®ã¿ï¼‰

ã€Œå‰²åˆã§è¡¨ç¤ºã€ã‚ªãƒ³æ™‚ã¯ã€å„ãƒãƒ¼ãƒ‰ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã¨å„ã‚¯ãƒ©ã‚¹ã®æ•°ãŒå‰²åˆï¼ˆç¢ºç‡ï¼‰ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
                    """
                )
            else:
                st.markdown(
                    """
**å„ãƒãƒ¼ãƒ‰ã®è¡¨ç¤ºå†…å®¹ï¼š**
- **åˆ†å‰²æ¡ä»¶**: ç‰¹å¾´é‡ <= é–¾å€¤ï¼ˆå†…éƒ¨ãƒãƒ¼ãƒ‰ã®ã¿ï¼‰
- **gini/entropy**: ä¸ç´”åº¦ï¼ˆ0ã«è¿‘ã„ã»ã©ç´”ç²‹ï¼‰
- **samples**: ã‚µãƒ³ãƒ—ãƒ«æ•°
- **value**: å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆåˆ†é¡ï¼‰ã¾ãŸã¯äºˆæ¸¬å€¤ï¼ˆå›å¸°ï¼‰
- **class**: æœ€ã‚‚å¤šã„ã‚¯ãƒ©ã‚¹ï¼ˆåˆ†é¡ã®ã¿ï¼‰

ã€Œå‰²åˆã§è¡¨ç¤ºã€ã‚’ã‚ªãƒ³ã«ã™ã‚‹ã¨ã€ç¢ºç‡è¡¨ç¤ºã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™ã€‚
                    """
                )

    with tab_text:
        tree_text = export_text(model, feature_names=feature_cols, max_depth=min(max_depth, 4))
        st.code(tree_text, language="text")

    # --- Predicted vs Actual (regression) ---
    if is_regression:
        st.markdown("### äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤")
        fig_pred = go.Figure()
        fig_pred.add_trace(go.Scatter(
            x=y_test, y=y_pred, mode="markers",
            marker=dict(color="steelblue", opacity=0.6),
            name="ãƒ‡ãƒ¼ã‚¿",
        ))
        min_val = min(float(np.min(y_test)), float(np.min(y_pred)))
        max_val = max(float(np.max(y_test)), float(np.max(y_pred)))
        fig_pred.add_trace(go.Scatter(
            x=[min_val, max_val], y=[min_val, max_val],
            mode="lines", line=dict(color="red", dash="dash"), name="å®Œå…¨äºˆæ¸¬",
        ))
        fig_pred.update_layout(title="äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤", xaxis_title="å®Ÿæ¸¬å€¤", yaxis_title="äºˆæ¸¬å€¤")
        st.plotly_chart(fig_pred, width="stretch")
