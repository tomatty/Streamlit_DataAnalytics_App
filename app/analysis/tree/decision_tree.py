"""
Decision Tree analysis module.
Supports both classification and regression tasks.
"""
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_text
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    r2_score, mean_squared_error, mean_absolute_error,
)
from sklearn.preprocessing import LabelEncoder


def show_decision_tree(df: pd.DataFrame):
    """Display Decision Tree analysis interface."""
    st.subheader("ğŸŒ³ æ±ºå®šæœ¨åˆ†æ")

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    all_cols = df.columns.tolist()

    if len(all_cols) < 2:
        st.warning("æ±ºå®šæœ¨åˆ†æã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    col1, col2 = st.columns(2)
    with col1:
        target_col = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰", all_cols, key="dt_target")
    with col2:
        task_type = st.radio(
            "ã‚¿ã‚¹ã‚¯ç¨®åˆ¥",
            ["åˆ†é¡ï¼ˆClassificationï¼‰", "å›å¸°ï¼ˆRegressionï¼‰"],
            key="dt_task",
            horizontal=True,
        )

    feature_cols = st.multiselect(
        "èª¬æ˜å¤‰æ•°ï¼ˆç‰¹å¾´é‡ï¼‰",
        [c for c in numeric_cols if c != target_col],
        default=[c for c in numeric_cols if c != target_col][:min(5, len(numeric_cols))],
        key="dt_features",
    )

    if len(feature_cols) < 1:
        st.info("å°‘ãªãã¨ã‚‚1ã¤ã®èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    col3, col4, col5 = st.columns(3)
    with col3:
        max_depth = st.slider("æœ€å¤§æ·±ã•ï¼ˆmax_depthï¼‰", min_value=1, max_value=10, value=4, key="dt_depth")
    with col4:
        min_samples_split = st.slider("åˆ†å‰²æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°", min_value=2, max_value=20, value=5, key="dt_mss")
    with col5:
        test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ", min_value=0.1, max_value=0.4, value=0.2, step=0.05, key="dt_test")

    if st.button("æ±ºå®šæœ¨åˆ†æã‚’å®Ÿè¡Œ", type="primary", key="dt_run"):
        try:
            data_subset = df[feature_cols + [target_col]].dropna()

            if len(data_subset) < 10:
                st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½10è¡Œå¿…è¦ï¼‰ã€‚")
                return

            X = data_subset[feature_cols]
            y_raw = data_subset[target_col]

            is_regression = task_type.startswith("å›å¸°")

            if is_regression:
                y = y_raw.astype(float)
                model = DecisionTreeRegressor(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42,
                )
            else:
                le = LabelEncoder()
                y = le.fit_transform(y_raw.astype(str))
                model = DecisionTreeClassifier(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42,
                )

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )

            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            st.success("æ±ºå®šæœ¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

            # --- Metrics ---
            st.markdown("### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™")

            if is_regression:
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                mae = mean_absolute_error(y_test, y_pred)
                cv_scores = cross_val_score(model, X, y, cv=5, scoring="r2")

                m_cols = st.columns(4)
                with m_cols[0]:
                    with st.container(border=True):
                        st.metric("RÂ²ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{r2:.4f}")
                with m_cols[1]:
                    with st.container(border=True):
                        st.metric("RMSE", f"{rmse:.4f}")
                with m_cols[2]:
                    with st.container(border=True):
                        st.metric("MAE", f"{mae:.4f}")
                with m_cols[3]:
                    with st.container(border=True):
                        st.metric("CV RÂ²ï¼ˆå¹³å‡ï¼‰", f"{cv_scores.mean():.4f}")

                with st.expander("ğŸ“– å›å¸°æŒ‡æ¨™ã®è§£é‡ˆ"):
                    st.markdown(
                        f"""
**RÂ²**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ±ºå®šä¿‚æ•°ã€‚1ã«è¿‘ã„ã»ã©è‰¯ã„äºˆæ¸¬ã€‚

**RMSE / MAE**: äºˆæ¸¬èª¤å·®ã€‚ç›®çš„å¤‰æ•°ã¨åŒã˜å˜ä½ã§è§£é‡ˆã§ãã‚‹ã€‚

**CV RÂ²**: 5-foldäº¤å·®æ¤œè¨¼ã®å¹³å‡RÂ²ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: RÂ²={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, CV RÂ²={cv_scores.mean():.4f}
                        """
                    )
            else:
                acc = accuracy_score(y_test, y_pred)
                cv_scores = cross_val_score(model, X, y, cv=5, scoring="accuracy")

                m_cols = st.columns(3)
                with m_cols[0]:
                    with st.container(border=True):
                        st.metric("æ­£è§£ç‡ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{acc:.4f}")
                with m_cols[1]:
                    with st.container(border=True):
                        st.metric("CV æ­£è§£ç‡ï¼ˆå¹³å‡ï¼‰", f"{cv_scores.mean():.4f}")
                with m_cols[2]:
                    with st.container(border=True):
                        st.metric("æœ¨ã®æ·±ã•", f"{model.get_depth()}")

                # Classification report
                st.markdown("#### åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
                report_dict = classification_report(
                    y_test, y_pred,
                    target_names=le.classes_.astype(str),
                    output_dict=True,
                )
                report_df = pd.DataFrame(report_dict).T
                st.dataframe(
                    report_df.style.format("{:.3f}", subset=["precision", "recall", "f1-score"]),
                    use_container_width=True,
                )

                # Confusion matrix
                st.markdown("#### æ··åŒè¡Œåˆ—")
                cm = confusion_matrix(y_test, y_pred)
                fig_cm = px.imshow(
                    cm,
                    labels=dict(x="äºˆæ¸¬ã‚¯ãƒ©ã‚¹", y="å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹", color="ä»¶æ•°"),
                    x=le.classes_.astype(str),
                    y=le.classes_.astype(str),
                    text_auto=True,
                    color_continuous_scale="Blues",
                )
                fig_cm.update_layout(title="æ··åŒè¡Œåˆ—")
                st.plotly_chart(fig_cm, use_container_width=True)

                with st.expander("ğŸ“– åˆ†é¡æŒ‡æ¨™ã®è§£é‡ˆ"):
                    st.markdown(
                        f"""
**æ­£è§£ç‡ï¼ˆAccuracyï¼‰**: å…¨äºˆæ¸¬ã®ã†ã¡æ­£ã—ãåˆ†é¡ã•ã‚ŒãŸå‰²åˆã€‚ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒã‚ã‚‹å ´åˆã¯ä»–ã®æŒ‡æ¨™ã‚‚ç¢ºèªã€‚

**Precisionï¼ˆé©åˆç‡ï¼‰**: ã€Œæ­£ã¨äºˆæ¸¬ã—ãŸã‚‚ã®ã€ã®ã†ã¡å®Ÿéš›ã«æ­£ã®å‰²åˆã€‚

**Recallï¼ˆå†ç¾ç‡ï¼‰**: ã€Œå®Ÿéš›ã«æ­£ã®ã‚‚ã®ã€ã®ã†ã¡æ­£ã¨äºˆæ¸¬ã§ããŸå‰²åˆã€‚

**F1ã‚¹ã‚³ã‚¢**: Precisionã¨Recallã®èª¿å’Œå¹³å‡ã€‚

**CV æ­£è§£ç‡**: 5-foldäº¤å·®æ¤œè¨¼ã®å¹³å‡æ­£è§£ç‡ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: æ­£è§£ç‡={acc:.4f}, CV={cv_scores.mean():.4f}Â±{cv_scores.std():.4f}
                        """
                    )

            # --- Feature Importance ---
            st.markdown("### ç‰¹å¾´é‡ã®é‡è¦åº¦")
            importance_df = pd.DataFrame({
                "ç‰¹å¾´é‡": feature_cols,
                "é‡è¦åº¦": model.feature_importances_,
            }).sort_values("é‡è¦åº¦", ascending=False)

            fig_imp = px.bar(
                importance_df,
                x="é‡è¦åº¦",
                y="ç‰¹å¾´é‡",
                orientation="h",
                title="ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆGiniä¸ç´”åº¦ãƒ™ãƒ¼ã‚¹ï¼‰",
                color="é‡è¦åº¦",
                color_continuous_scale="Blues",
            )
            fig_imp.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig_imp, use_container_width=True)

            # --- Tree structure (text) ---
            st.markdown("### æœ¨ã®æ§‹é€ ï¼ˆãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºï¼‰")
            tree_text = export_text(model, feature_names=feature_cols, max_depth=min(max_depth, 4))
            st.code(tree_text, language="text")

            # --- Predicted vs Actual (regression) ---
            if is_regression:
                st.markdown("### äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤")
                fig_pred = go.Figure()
                fig_pred.add_trace(go.Scatter(
                    x=y_test, y=y_pred, mode="markers",
                    marker=dict(color="steelblue", opacity=0.6),
                    name="ãƒ‡ãƒ¼ã‚¿",
                ))
                min_val, max_val = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
                fig_pred.add_trace(go.Scatter(
                    x=[min_val, max_val], y=[min_val, max_val],
                    mode="lines", line=dict(color="red", dash="dash"), name="å®Œå…¨äºˆæ¸¬",
                ))
                fig_pred.update_layout(title="äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤", xaxis_title="å®Ÿæ¸¬å€¤", yaxis_title="äºˆæ¸¬å€¤")
                st.plotly_chart(fig_pred, use_container_width=True)

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
