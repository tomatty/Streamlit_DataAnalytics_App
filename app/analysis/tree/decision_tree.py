"""
Decision Tree analysis module.
Supports both classification and regression tasks.
"""
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    mean_absolute_error,
    mean_squared_error,
    r2_score,
)
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_text, plot_tree

matplotlib.rcParams["font.family"] = "Noto Sans CJK JP"

_SS = "dt_results"  # session_state key


def show_decision_tree(df: pd.DataFrame):
    """Display Decision Tree analysis interface."""
    st.subheader("ğŸŒ³ æ±ºå®šæœ¨åˆ†æ")

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    all_cols = df.columns.tolist()

    if len(all_cols) < 2:
        st.warning("æ±ºå®šæœ¨åˆ†æã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    col1, col2 = st.columns(2)
    with col1:
        target_col = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰", all_cols, key="dt_target")
    with col2:
        task_type = st.radio(
            "ã‚¿ã‚¹ã‚¯ç¨®åˆ¥",
            ["åˆ†é¡ï¼ˆClassificationï¼‰", "å›å¸°ï¼ˆRegressionï¼‰"],
            key="dt_task",
            horizontal=True,
        )

    feature_cols = st.multiselect(
        "èª¬æ˜å¤‰æ•°ï¼ˆç‰¹å¾´é‡ï¼‰",
        [c for c in numeric_cols if c != target_col],
        default=[c for c in numeric_cols if c != target_col][:min(5, len(numeric_cols))],
        key="dt_features",
    )

    if len(feature_cols) < 1:
        st.info("å°‘ãªãã¨ã‚‚1ã¤ã®èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    col3, col4, col5 = st.columns(3)
    with col3:
        max_depth = st.slider("æœ€å¤§æ·±ã•ï¼ˆmax_depthï¼‰", min_value=1, max_value=10, value=4, key="dt_depth")
    with col4:
        min_samples_split = st.slider("åˆ†å‰²æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°", min_value=2, max_value=20, value=5, key="dt_mss")
    with col5:
        test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ", min_value=0.1, max_value=0.4, value=0.2, step=0.05, key="dt_test")

    if st.button("æ±ºå®šæœ¨åˆ†æã‚’å®Ÿè¡Œ", type="primary", key="dt_run"):
        try:
            data_subset = df[feature_cols + [target_col]].dropna()

            if len(data_subset) < 10:
                st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½10è¡Œå¿…è¦ï¼‰ã€‚")
                return

            X = data_subset[feature_cols]
            y_raw = data_subset[target_col]
            is_regression = task_type.startswith("å›å¸°")

            le = None
            if is_regression:
                y = y_raw.astype(float)
                model = DecisionTreeRegressor(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42,
                )
            else:
                le = LabelEncoder()
                y = le.fit_transform(y_raw.astype(str))
                model = DecisionTreeClassifier(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    random_state=42,
                )

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            if is_regression:
                n_cv = min(5, len(y) // 2)
                cv_scores = cross_val_score(model, X, y, cv=n_cv, scoring="r2") if n_cv >= 2 else None
                metrics = {
                    "r2": r2_score(y_test, y_pred),
                    "rmse": float(np.sqrt(mean_squared_error(y_test, y_pred))),
                    "mae": float(mean_absolute_error(y_test, y_pred)),
                    "cv_mean": float(cv_scores.mean()) if cv_scores is not None else None,
                    "cv_std": float(cv_scores.std()) if cv_scores is not None else None,
                }
            else:
                min_class_count = int(np.bincount(y).min())
                n_cv = min(5, min_class_count)
                cv_scores = cross_val_score(model, X, y, cv=n_cv, scoring="accuracy") if n_cv >= 2 else None
                metrics = {
                    "acc": float(accuracy_score(y_test, y_pred)),
                    "cv_mean": float(cv_scores.mean()) if cv_scores is not None else None,
                    "cv_std": float(cv_scores.std()) if cv_scores is not None else None,
                    "depth": int(model.get_depth()),
                }

            # Save to session_state
            st.session_state[_SS] = {
                "model": model,
                "feature_cols": feature_cols,
                "is_regression": is_regression,
                "max_depth": max_depth,
                "le": le,
                "y_test": y_test,
                "y_pred": y_pred,
                "X": X,
                "metrics": metrics,
            }

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return

    # ---- Render results from session_state ----
    if _SS not in st.session_state:
        return

    res = st.session_state[_SS]
    model = res["model"]
    feature_cols = res["feature_cols"]
    is_regression = res["is_regression"]
    max_depth = res["max_depth"]
    le = res["le"]
    y_test = res["y_test"]
    y_pred = res["y_pred"]
    X = res["X"]
    metrics = res["metrics"]

    st.success("æ±ºå®šæœ¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    # --- Metrics ---
    st.markdown("### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™")

    if is_regression:
        r2, rmse, mae = metrics["r2"], metrics["rmse"], metrics["mae"]
        m_cols = st.columns(4)
        with m_cols[0]:
            with st.container(border=True):
                st.metric("RÂ²ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{r2:.4f}")
        with m_cols[1]:
            with st.container(border=True):
                st.metric("RMSE", f"{rmse:.4f}")
        with m_cols[2]:
            with st.container(border=True):
                st.metric("MAE", f"{mae:.4f}")
        with m_cols[3]:
            with st.container(border=True):
                cv_val = f"{metrics['cv_mean']:.4f}" if metrics["cv_mean"] is not None else "N/A"
                st.metric("CV RÂ²ï¼ˆå¹³å‡ï¼‰", cv_val)

        if metrics["cv_mean"] is None:
            st.warning("ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚äº¤å·®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        with st.expander("ğŸ“– å›å¸°æŒ‡æ¨™ã®è§£é‡ˆ"):
            cv_detail = f"CV RÂ²={metrics['cv_mean']:.4f}" if metrics["cv_mean"] is not None else "CV: ã‚¹ã‚­ãƒƒãƒ—"
            st.markdown(
                f"""
**RÂ²**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ±ºå®šä¿‚æ•°ã€‚1ã«è¿‘ã„ã»ã©è‰¯ã„äºˆæ¸¬ã€‚

**RMSE / MAE**: äºˆæ¸¬èª¤å·®ã€‚ç›®çš„å¤‰æ•°ã¨åŒã˜å˜ä½ã§è§£é‡ˆã§ãã‚‹ã€‚

**CV RÂ²**: äº¤å·®æ¤œè¨¼ã®å¹³å‡RÂ²ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: RÂ²={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, {cv_detail}
                """
            )
    else:
        acc = metrics["acc"]
        m_cols = st.columns(3)
        with m_cols[0]:
            with st.container(border=True):
                st.metric("æ­£è§£ç‡ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{acc:.4f}")
        with m_cols[1]:
            with st.container(border=True):
                cv_val = f"{metrics['cv_mean']:.4f}" if metrics["cv_mean"] is not None else "N/A"
                st.metric("CV æ­£è§£ç‡ï¼ˆå¹³å‡ï¼‰", cv_val)
        with m_cols[2]:
            with st.container(border=True):
                st.metric("æœ¨ã®æ·±ã•", f"{metrics['depth']}")

        if metrics["cv_mean"] is None:
            st.warning("ä¸€éƒ¨ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚äº¤å·®æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        st.markdown("#### åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
        report_dict = classification_report(
            y_test, y_pred,
            target_names=le.classes_.astype(str),
            output_dict=True,
        )
        report_df = pd.DataFrame(report_dict).T
        st.dataframe(
            report_df.style.format("{:.3f}", subset=["precision", "recall", "f1-score"]),
            use_container_width=True,
        )

        st.markdown("#### æ··åŒè¡Œåˆ—")
        cm = confusion_matrix(y_test, y_pred)
        fig_cm = px.imshow(
            cm,
            labels=dict(x="äºˆæ¸¬ã‚¯ãƒ©ã‚¹", y="å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹", color="ä»¶æ•°"),
            x=le.classes_.astype(str),
            y=le.classes_.astype(str),
            text_auto=True,
            color_continuous_scale="Blues",
        )
        fig_cm.update_layout(title="æ··åŒè¡Œåˆ—")
        st.plotly_chart(fig_cm, use_container_width=True)

        with st.expander("ğŸ“– åˆ†é¡æŒ‡æ¨™ã®è§£é‡ˆ"):
            st.markdown(
                f"""
**æ­£è§£ç‡ï¼ˆAccuracyï¼‰**: å…¨äºˆæ¸¬ã®ã†ã¡æ­£ã—ãåˆ†é¡ã•ã‚ŒãŸå‰²åˆã€‚

**Precision / Recall / F1**: ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ»èª¿å’Œå¹³å‡ã€‚

**CV æ­£è§£ç‡**: äº¤å·®æ¤œè¨¼ã®å¹³å‡æ­£è§£ç‡ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: æ­£è§£ç‡={acc:.4f}{f", CV={metrics['cv_mean']:.4f}Â±{metrics['cv_std']:.4f}" if metrics['cv_mean'] is not None else ", CV: ã‚¹ã‚­ãƒƒãƒ—"}
                """
            )

    # --- Feature Importance ---
    st.markdown("### ç‰¹å¾´é‡ã®é‡è¦åº¦")
    importance_df = pd.DataFrame({
        "ç‰¹å¾´é‡": feature_cols,
        "é‡è¦åº¦": model.feature_importances_,
    }).sort_values("é‡è¦åº¦", ascending=False)

    fig_imp = px.bar(
        importance_df,
        x="é‡è¦åº¦",
        y="ç‰¹å¾´é‡",
        orientation="h",
        title="ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆGiniä¸ç´”åº¦ãƒ™ãƒ¼ã‚¹ï¼‰",
        color="é‡è¦åº¦",
        color_continuous_scale="Blues",
    )
    fig_imp.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
    st.plotly_chart(fig_imp, use_container_width=True)

    # --- Tree visualization ---
    st.markdown("### æœ¨ã®æ§‹é€ ")
    tab_plot, tab_text = st.tabs(["æ¨¹å½¢å›³", "ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º"])

    with tab_plot:
        display_depth = st.slider(
            "è¡¨ç¤ºã™ã‚‹æ·±ã•",
            min_value=1,
            max_value=min(max_depth, 6),
            value=min(3, max_depth),
            key="dt_display_depth",
        )
        class_names = le.classes_.astype(str).tolist() if not is_regression else None
        actual_depth = model.get_depth()
        # Cap visible leaves to avoid over-expanding the figure
        visible_leaves = min(2 ** display_depth, model.get_n_leaves())
        fig_width = max(10, min(visible_leaves * 2.5, 48))
        fig_height = max(5, display_depth * 3.2)
        fontsize = max(9, 13 - display_depth)
        fig_tree, ax = plt.subplots(figsize=(fig_width, fig_height))
        plot_tree(
            model,
            max_depth=display_depth,
            feature_names=feature_cols,
            class_names=class_names,
            filled=True,
            rounded=True,
            fontsize=fontsize,
            impurity=True,
            proportion=False,
            ax=ax,
        )
        ax.set_title(
            f"æ±ºå®šæœ¨ï¼ˆè¡¨ç¤ºæ·±ã•: {display_depth} / å®Ÿéš›ã®æ·±ã•: {actual_depth}ï¼‰",
            fontsize=12,
        )
        st.pyplot(fig_tree, use_container_width=True)
        plt.close(fig_tree)

    with tab_text:
        tree_text = export_text(model, feature_names=feature_cols, max_depth=min(max_depth, 4))
        st.code(tree_text, language="text")

    # --- Predicted vs Actual (regression) ---
    if is_regression:
        st.markdown("### äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤")
        fig_pred = go.Figure()
        fig_pred.add_trace(go.Scatter(
            x=y_test, y=y_pred, mode="markers",
            marker=dict(color="steelblue", opacity=0.6),
            name="ãƒ‡ãƒ¼ã‚¿",
        ))
        min_val = min(float(np.min(y_test)), float(np.min(y_pred)))
        max_val = max(float(np.max(y_test)), float(np.max(y_pred)))
        fig_pred.add_trace(go.Scatter(
            x=[min_val, max_val], y=[min_val, max_val],
            mode="lines", line=dict(color="red", dash="dash"), name="å®Œå…¨äºˆæ¸¬",
        ))
        fig_pred.update_layout(title="äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤", xaxis_title="å®Ÿæ¸¬å€¤", yaxis_title="äºˆæ¸¬å€¤")
        st.plotly_chart(fig_pred, use_container_width=True)
