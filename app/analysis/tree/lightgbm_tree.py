"""
LightGBM decision tree analysis module.
Supports both classification and regression tasks.
"""
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    r2_score, mean_squared_error, mean_absolute_error,
)
from sklearn.preprocessing import LabelEncoder

try:
    import lightgbm as lgb
except ImportError:
    lgb = None


def show_lightgbm_tree(df: pd.DataFrame):
    """Display LightGBM analysis interface."""
    st.subheader("âš¡ LightGBM æ±ºå®šæœ¨åˆ†æ")

    if lgb is None:
        st.error("lightgbmãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install lightgbm`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    all_cols = df.columns.tolist()

    if len(all_cols) < 2:
        st.warning("LightGBMåˆ†æã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    col1, col2 = st.columns(2)
    with col1:
        target_col = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰", all_cols, key="lgb_target")
    with col2:
        task_type = st.radio(
            "ã‚¿ã‚¹ã‚¯ç¨®åˆ¥",
            ["åˆ†é¡ï¼ˆClassificationï¼‰", "å›å¸°ï¼ˆRegressionï¼‰"],
            key="lgb_task",
            horizontal=True,
        )

    feature_cols = st.multiselect(
        "èª¬æ˜å¤‰æ•°ï¼ˆç‰¹å¾´é‡ï¼‰",
        [c for c in numeric_cols if c != target_col],
        default=[c for c in numeric_cols if c != target_col][:min(5, len(numeric_cols))],
        key="lgb_features",
    )

    if len(feature_cols) < 1:
        st.info("å°‘ãªãã¨ã‚‚1ã¤ã®èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    st.markdown("#### ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
    p_col1, p_col2, p_col3, p_col4 = st.columns(4)
    with p_col1:
        n_estimators = st.slider("æœ¨ã®æœ¬æ•°ï¼ˆn_estimatorsï¼‰", 50, 500, 100, step=50, key="lgb_n")
    with p_col2:
        learning_rate = st.select_slider(
            "å­¦ç¿’ç‡ï¼ˆlearning_rateï¼‰",
            options=[0.01, 0.05, 0.1, 0.2, 0.3],
            value=0.1,
            key="lgb_lr",
        )
    with p_col3:
        max_depth = st.slider("æœ€å¤§æ·±ã•ï¼ˆmax_depthï¼‰", -1, 10, 4, key="lgb_depth",
                              help="-1 ã¯ç„¡åˆ¶é™")
    with p_col4:
        test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‰²åˆ", 0.1, 0.4, 0.2, step=0.05, key="lgb_test")

    num_leaves = st.slider("è‘‰ã®æœ€å¤§æ•°ï¼ˆnum_leavesï¼‰", 4, 128, 31, key="lgb_leaves")

    if st.button("LightGBMåˆ†æã‚’å®Ÿè¡Œ", type="primary", key="lgb_run"):
        try:
            data_subset = df[feature_cols + [target_col]].dropna()

            if len(data_subset) < 10:
                st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½10è¡Œå¿…è¦ï¼‰ã€‚")
                return

            X = data_subset[feature_cols]
            y_raw = data_subset[target_col]

            is_regression = task_type.startswith("å›å¸°")

            if is_regression:
                y = y_raw.astype(float)
                model = lgb.LGBMRegressor(
                    n_estimators=n_estimators,
                    learning_rate=learning_rate,
                    max_depth=max_depth,
                    num_leaves=num_leaves,
                    random_state=42,
                    verbose=-1,
                )
                scoring = "r2"
            else:
                le = LabelEncoder()
                y = le.fit_transform(y_raw.astype(str))
                n_classes = len(le.classes_)
                objective = "multiclass" if n_classes > 2 else "binary"
                model = lgb.LGBMClassifier(
                    n_estimators=n_estimators,
                    learning_rate=learning_rate,
                    max_depth=max_depth,
                    num_leaves=num_leaves,
                    objective=objective,
                    random_state=42,
                    verbose=-1,
                )
                scoring = "accuracy"

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )

            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            cv_scores = cross_val_score(model, X, y, cv=5, scoring=scoring)

            st.success("LightGBMåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

            # --- Metrics ---
            st.markdown("### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™")

            if is_regression:
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                mae = mean_absolute_error(y_test, y_pred)

                m_cols = st.columns(4)
                with m_cols[0]:
                    with st.container(border=True):
                        st.metric("RÂ²ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{r2:.4f}")
                with m_cols[1]:
                    with st.container(border=True):
                        st.metric("RMSE", f"{rmse:.4f}")
                with m_cols[2]:
                    with st.container(border=True):
                        st.metric("MAE", f"{mae:.4f}")
                with m_cols[3]:
                    with st.container(border=True):
                        st.metric("CV RÂ²ï¼ˆå¹³å‡ï¼‰", f"{cv_scores.mean():.4f}")

                with st.expander("ğŸ“– å›å¸°æŒ‡æ¨™ã®è§£é‡ˆ"):
                    st.markdown(
                        f"""
**RÂ²**: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ±ºå®šä¿‚æ•°ã€‚1ã«è¿‘ã„ã»ã©è‰¯ã„äºˆæ¸¬ã€‚

**RMSE / MAE**: äºˆæ¸¬èª¤å·®ã€‚ç›®çš„å¤‰æ•°ã¨åŒã˜å˜ä½ã§è§£é‡ˆã§ãã‚‹ã€‚

**CV RÂ²**: 5-foldäº¤å·®æ¤œè¨¼ã®å¹³å‡RÂ²ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: RÂ²={r2:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, CV RÂ²={cv_scores.mean():.4f}Â±{cv_scores.std():.4f}
                        """
                    )
            else:
                acc = accuracy_score(y_test, y_pred)

                m_cols = st.columns(3)
                with m_cols[0]:
                    with st.container(border=True):
                        st.metric("æ­£è§£ç‡ï¼ˆãƒ†ã‚¹ãƒˆï¼‰", f"{acc:.4f}")
                with m_cols[1]:
                    with st.container(border=True):
                        st.metric("CV æ­£è§£ç‡ï¼ˆå¹³å‡ï¼‰", f"{cv_scores.mean():.4f}")
                with m_cols[2]:
                    with st.container(border=True):
                        st.metric("CV æ¨™æº–åå·®", f"{cv_scores.std():.4f}")

                # Classification report
                st.markdown("#### åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ")
                report_dict = classification_report(
                    y_test, y_pred,
                    target_names=le.classes_.astype(str),
                    output_dict=True,
                )
                report_df = pd.DataFrame(report_dict).T
                st.dataframe(
                    report_df.style.format("{:.3f}", subset=["precision", "recall", "f1-score"]),
                    use_container_width=True,
                )

                # Confusion matrix
                st.markdown("#### æ··åŒè¡Œåˆ—")
                cm = confusion_matrix(y_test, y_pred)
                fig_cm = px.imshow(
                    cm,
                    labels=dict(x="äºˆæ¸¬ã‚¯ãƒ©ã‚¹", y="å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹", color="ä»¶æ•°"),
                    x=le.classes_.astype(str),
                    y=le.classes_.astype(str),
                    text_auto=True,
                    color_continuous_scale="Blues",
                )
                fig_cm.update_layout(title="æ··åŒè¡Œåˆ—")
                st.plotly_chart(fig_cm, use_container_width=True)

                with st.expander("ğŸ“– åˆ†é¡æŒ‡æ¨™ã®è§£é‡ˆ"):
                    st.markdown(
                        f"""
**æ­£è§£ç‡ï¼ˆAccuracyï¼‰**: å…¨äºˆæ¸¬ã®ã†ã¡æ­£ã—ãåˆ†é¡ã•ã‚ŒãŸå‰²åˆã€‚

**Precision / Recall / F1**: ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦ãƒ»å†ç¾ç‡ãƒ»èª¿å’Œå¹³å‡ã€‚

**CV æ­£è§£ç‡**: 5-foldäº¤å·®æ¤œè¨¼ã®å¹³å‡æ­£è§£ç‡ã€‚éå­¦ç¿’ã®æ¤œå‡ºã«ä½¿ç”¨ã€‚

ç¾åœ¨ã®å€¤: æ­£è§£ç‡={acc:.4f}, CV={cv_scores.mean():.4f}Â±{cv_scores.std():.4f}
                        """
                    )

            # --- Feature Importance ---
            st.markdown("### ç‰¹å¾´é‡ã®é‡è¦åº¦")
            importance_tab1, importance_tab2 = st.tabs(["gainï¼ˆæƒ…å ±åˆ©å¾—ï¼‰", "splitï¼ˆåˆ†å‰²å›æ•°ï¼‰"])

            imp_gain = model.feature_importances_
            imp_df_gain = pd.DataFrame({
                "ç‰¹å¾´é‡": feature_cols,
                "é‡è¦åº¦ï¼ˆgainï¼‰": imp_gain,
            }).sort_values("é‡è¦åº¦ï¼ˆgainï¼‰", ascending=False)

            with importance_tab1:
                fig_gain = px.bar(
                    imp_df_gain,
                    x="é‡è¦åº¦ï¼ˆgainï¼‰",
                    y="ç‰¹å¾´é‡",
                    orientation="h",
                    title="ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆgain: æƒ…å ±åˆ©å¾—ã®åˆè¨ˆï¼‰",
                    color="é‡è¦åº¦ï¼ˆgainï¼‰",
                    color_continuous_scale="Greens",
                )
                fig_gain.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
                st.plotly_chart(fig_gain, use_container_width=True)

            with importance_tab2:
                booster = model.booster_
                imp_split = booster.feature_importance(importance_type="split")
                imp_df_split = pd.DataFrame({
                    "ç‰¹å¾´é‡": feature_cols,
                    "é‡è¦åº¦ï¼ˆsplitï¼‰": imp_split,
                }).sort_values("é‡è¦åº¦ï¼ˆsplitï¼‰", ascending=False)

                fig_split = px.bar(
                    imp_df_split,
                    x="é‡è¦åº¦ï¼ˆsplitï¼‰",
                    y="ç‰¹å¾´é‡",
                    orientation="h",
                    title="ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆsplit: ä½¿ç”¨ã•ã‚ŒãŸåˆ†å‰²å›æ•°ï¼‰",
                    color="é‡è¦åº¦ï¼ˆsplitï¼‰",
                    color_continuous_scale="Oranges",
                )
                fig_split.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
                st.plotly_chart(fig_split, use_container_width=True)

            with st.expander("ğŸ“– ç‰¹å¾´é‡é‡è¦åº¦ã®è§£é‡ˆ"):
                st.markdown(
                    """
**gainï¼ˆæƒ…å ±åˆ©å¾—ï¼‰**: ãã®ç‰¹å¾´é‡ãŒä½¿ã‚ã‚ŒãŸåˆ†å²ã§ã®æƒ…å ±åˆ©å¾—ã®åˆè¨ˆã€‚äºˆæ¸¬ã¸ã®å®Ÿè³ªçš„ãªè²¢çŒ®åº¦ã‚’è¡¨ã™ã€‚

**splitï¼ˆåˆ†å‰²å›æ•°ï¼‰**: ãã®ç‰¹å¾´é‡ãŒæœ¨å…¨ä½“ã§åˆ†å²ã«ä½¿ã‚ã‚ŒãŸå›æ•°ã€‚é »ç¹ã«ä½¿ã‚ã‚Œã‚‹ã»ã©é«˜ã„ã€‚

ä¸€èˆ¬çš„ã« **gain** ãŒãƒ¢ãƒ‡ãƒ«ã¸ã®è²¢çŒ®ã‚’ã‚ˆã‚Šæ­£ç¢ºã«åæ˜ ã—ã¾ã™ã€‚
                    """
                )

            # --- Learning curves (loss) ---
            st.markdown("### å­¦ç¿’æ›²ç·šï¼ˆLightGBM ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°æå¤±ï¼‰")
            model_cv = lgb.LGBMRegressor(**model.get_params()) if is_regression else lgb.LGBMClassifier(**model.get_params())
            eval_metric = "rmse" if is_regression else "binary_logloss" if len(np.unique(y)) == 2 else "multi_logloss"
            callbacks = [lgb.log_evaluation(period=-1), lgb.record_evaluation(evals_result := {})]
            model_cv.fit(
                X_train, y_train,
                eval_set=[(X_train, y_train), (X_test, y_test)],
                eval_metric=eval_metric,
                callbacks=callbacks,
            )

            metric_key = list(evals_result.get("training", {}).keys())
            if metric_key:
                mk = metric_key[0]
                train_loss = evals_result["training"][mk]
                valid_loss = evals_result["valid_1"][mk]
                fig_lc = go.Figure()
                fig_lc.add_trace(go.Scatter(
                    x=list(range(1, len(train_loss) + 1)), y=train_loss,
                    mode="lines", name="è¨“ç·´", line=dict(color="blue"),
                ))
                fig_lc.add_trace(go.Scatter(
                    x=list(range(1, len(valid_loss) + 1)), y=valid_loss,
                    mode="lines", name="ãƒ†ã‚¹ãƒˆ", line=dict(color="orange"),
                ))
                fig_lc.update_layout(
                    title=f"å­¦ç¿’æ›²ç·šï¼ˆ{mk}ï¼‰",
                    xaxis_title="ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°å›æ•°",
                    yaxis_title=mk,
                )
                st.plotly_chart(fig_lc, use_container_width=True)

            # --- Predicted vs Actual (regression) ---
            if is_regression:
                st.markdown("### äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤")
                fig_pred = go.Figure()
                fig_pred.add_trace(go.Scatter(
                    x=y_test, y=y_pred, mode="markers",
                    marker=dict(color="green", opacity=0.6), name="ãƒ‡ãƒ¼ã‚¿",
                ))
                min_val = min(float(np.min(y_test)), float(np.min(y_pred)))
                max_val = max(float(np.max(y_test)), float(np.max(y_pred)))
                fig_pred.add_trace(go.Scatter(
                    x=[min_val, max_val], y=[min_val, max_val],
                    mode="lines", line=dict(color="red", dash="dash"), name="å®Œå…¨äºˆæ¸¬",
                ))
                fig_pred.update_layout(title="äºˆæ¸¬å€¤ vs å®Ÿæ¸¬å€¤", xaxis_title="å®Ÿæ¸¬å€¤", yaxis_title="äºˆæ¸¬å€¤")
                st.plotly_chart(fig_pred, use_container_width=True)

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
