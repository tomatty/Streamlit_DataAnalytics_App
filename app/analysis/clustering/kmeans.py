"""
K-Means Clustering module.
"""
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score


def show_kmeans_clustering(df: pd.DataFrame):
    """Display K-Means clustering interface."""
    st.subheader("ğŸ“Š K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")

    with st.expander("ğŸ“– ä¸€èˆ¬çš„ãªåˆ†ææ‰‹é †", expanded=False):
        st.markdown(
            """
### K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®åŸºæœ¬çš„ãªæµã‚Œ

**1. ç›®çš„ã®æ˜ç¢ºåŒ–**
- é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³: è³¼è²·è¡Œå‹•ã‚„å±æ€§ã§é¡§å®¢ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
- å•†å“åˆ†é¡: é¡ä¼¼å•†å“ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
- ç•°å¸¸æ¤œå‡º: æ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å¤–ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç™ºè¦‹
- ãƒ‡ãƒ¼ã‚¿åœ§ç¸®: å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä»£è¡¨ç‚¹ã§è¦ç´„

**2. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**
- **ãƒ‡ãƒ¼ã‚¿å½¢å¼**:
  - è¡Œï¼šã‚µãƒ³ãƒ—ãƒ«/è¦³æ¸¬ï¼ˆä¾‹: é¡§å®¢ã€å•†å“ã€æ™‚ç‚¹ï¼‰
  - åˆ—ï¼šæ•°å€¤å‹å¤‰æ•°ï¼ˆä¾‹: è³¼è²·é¡ã€å¹´é½¢ã€é »åº¦ï¼‰
  - æœ€ä½2åˆ—ä»¥ä¸Šã®æ•°å€¤å‹å¤‰æ•°ãŒå¿…è¦
- **ãƒ‡ãƒ¼ã‚¿ä¾‹**:
  ```
  | é¡§å®¢ID | è³¼è²·é¡ | è³¼è²·å›æ•° | å¹³å‡å˜ä¾¡ | çµŒéæ—¥æ•° |
  |--------|-------|---------|---------|---------|
  | 1      | 50000 | 12      | 4167    | 5       |
  | 2      | 8000  | 2       | 4000    | 120     |
  | 3      | 150000| 45      | 3333    | 3       |
  ```
- **æ¨™æº–åŒ–ãŒé‡è¦**: å˜ä½ã®ç•°ãªã‚‹å¤‰æ•°ã‚’åŒã˜ã‚¹ã‚±ãƒ¼ãƒ«ã«æƒãˆã‚‹
- æ¬ æå€¤ã®å‡¦ç†ãŒå¿…è¦
- å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ãŸã‚äº‹å‰ç¢ºèª
- **ã‚«ãƒ†ã‚´ãƒªãƒ¼å¤‰æ•°ã®æ‰±ã„**:
  - K-Meansã¯ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’ä½¿ã†ãŸã‚ã€æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒå¿…é ˆ
  - **ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆæ¨å¥¨ï¼‰**: ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’0/1ã®ãƒã‚¤ãƒŠãƒªå¤‰æ•°ã«å¤‰æ›
    - ä¾‹: åœ°åŸŸï¼ˆæ±äº¬/å¤§é˜ª/åå¤å±‹ï¼‰â†’ åœ°åŸŸ_æ±äº¬ï¼ˆ0/1ï¼‰ã€åœ°åŸŸ_å¤§é˜ªï¼ˆ0/1ï¼‰ã€åœ°åŸŸ_åå¤å±‹ï¼ˆ0/1ï¼‰
  - **é †åºã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**: é †åºã®ã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆä½/ä¸­/é«˜ â†’ 1/2/3ï¼‰
  - ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒå¤šã„å ´åˆã¯æ¬¡å…ƒãŒå¢—ãˆã™ãã‚‹ãŸã‚æ³¨æ„
  - æ¨™æº–åŒ–ã‚’é©ç”¨ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æƒãˆã‚‹

**3. ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æ±ºå®š**
- **ã‚¨ãƒ«ãƒœãƒ¼æ³•**: ã‚¤ãƒŠãƒ¼ã‚·ãƒ£ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿å†…å¹³æ–¹å’Œï¼‰ã®æ¸›å°‘ãŒç·©ã‚„ã‹ã«ãªã‚‹ç‚¹
- **ã‚·ãƒ«ã‚¨ãƒƒãƒˆä¿‚æ•°**: 0.5ä»¥ä¸ŠãŒè‰¯å¥½ã€0.7ä»¥ä¸ŠãŒå„ªç§€
- **ãƒ“ã‚¸ãƒã‚¹è¦³ç‚¹**: å®Ÿå‹™çš„ã«æ„å‘³ã®ã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°
- ä¸€èˆ¬çš„ã«ã¯2-10å€‹ç¨‹åº¦ãŒè§£é‡ˆã—ã‚„ã™ã„

**4. çµæœã®è§£é‡ˆ**
- **ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒ**: å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ä»£è¡¨çš„ãªç‰¹å¾´
- **ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º**: å„ã‚¯ãƒ©ã‚¹ã‚¿ã«å±ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
- **ã‚¯ãƒ©ã‚¹ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«**: å„å¤‰æ•°ã®å¹³å‡å€¤ã‚„åˆ†å¸ƒ
- ãƒ“ã‚¸ãƒã‚¹çš„ãªå‘½å: ã€Œå„ªè‰¯é¡§å®¢ã€ã€Œä¼‘çœ é¡§å®¢ã€ãªã©

**5. æ´»ç”¨æ–¹æ³•**
- ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ–½ç­–ã®æœ€é©åŒ–
- ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°åºƒå‘Š
- åœ¨åº«ç®¡ç†ã®åŠ¹ç‡åŒ–
- æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

**6. æ³¨æ„ç‚¹**
- åˆæœŸå€¤ã«ã‚ˆã‚ŠçµæœãŒå¤‰ã‚ã‚‹ï¼ˆrandom_stateå›ºå®šã§å†ç¾æ€§ç¢ºä¿ï¼‰
- çƒå½¢ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’å‰æï¼ˆè¤‡é›‘ãªå½¢çŠ¶ã«ã¯ä¸å‘ãï¼‰
- å¤–ã‚Œå€¤ã«æ•æ„Ÿ
- ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’äº‹å‰ã«æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹
            """
        )

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()

    if len(numeric_cols) < 2:
        st.warning("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã¯å°‘ãªãã¨ã‚‚2ã¤ã®æ•°å€¤å‹åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    selected_cols = st.multiselect(
        "åˆ†æå¯¾è±¡åˆ—ã‚’é¸æŠ",
        numeric_cols,
        default=numeric_cols[:min(5, len(numeric_cols))]
    )

    if len(selected_cols) < 2:
        st.info("å°‘ãªãã¨ã‚‚2ã¤ã®åˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    col1, col2, col3 = st.columns(3)
    with col1:
        n_clusters = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", min_value=2, max_value=10, value=3)
    with col2:
        max_iter = st.slider("æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°", min_value=100, max_value=1000, value=300, step=50)
    with col3:
        standardize = st.checkbox("ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–", value=True)

    # Elbow method
    if st.checkbox("ã‚¨ãƒ«ãƒœãƒ¼æ³•ã§ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’æ±ºå®š"):
        show_elbow_method(df, selected_cols, standardize)

    if st.button("K-Meansã‚’å®Ÿè¡Œ", type="primary"):
        try:
            data_subset = df[selected_cols].dropna()

            if len(data_subset) < n_clusters:
                st.error("ãƒ‡ãƒ¼ã‚¿æ•°ãŒã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚ˆã‚Šå°‘ãªã„ã§ã™ã€‚")
                return

            # Standardize if requested
            if standardize:
                scaler = StandardScaler()
                X = scaler.fit_transform(data_subset)
            else:
                X = data_subset.values

            # Perform K-Means
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10, max_iter=max_iter)
            clusters = kmeans.fit_predict(X)

            # Silhouette score
            silhouette_avg = silhouette_score(X, clusters)

            st.success("K-Meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

            col1, col2 = st.columns(2)
            with col1:
                with st.container(border=True):
                    st.metric("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", n_clusters)
            with col2:
                with st.container(border=True):
                    st.metric("ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢", f"{silhouette_avg:.3f}")

            with st.expander("ğŸ“– ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã®è§£é‡ˆ"):
                st.markdown(
                    """
ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã¯ã€å„ãƒ‡ãƒ¼ã‚¿ç‚¹ãŒè‡ªã‚¯ãƒ©ã‚¹ã‚¿ã«å¯¾ã—ã¦ã©ã‚Œã ã‘é©åˆ‡ã«åˆ†é¡ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¤ºã™æŒ‡æ¨™ã§ã™ï¼ˆç¯„å›²: âˆ’1ã€œ+1ï¼‰ã€‚

| ã‚¹ã‚³ã‚¢ | è©•ä¾¡ |
|--------|------|
| 0.71 ã€œ 1.00 | éå¸¸ã«è‰¯ã„ã‚¯ãƒ©ã‚¹ã‚¿æ§‹é€  |
| 0.51 ã€œ 0.70 | å¦¥å½“ãªã‚¯ãƒ©ã‚¹ã‚¿æ§‹é€  |
| 0.26 ã€œ 0.50 | å¼±ã„ã‚¯ãƒ©ã‚¹ã‚¿æ§‹é€ ï¼ˆé‡è¤‡ã®å¯èƒ½æ€§ã‚ã‚Šï¼‰ |
| âˆ’1.00 ã€œ 0.25 | ã‚¯ãƒ©ã‚¹ã‚¿æ§‹é€ ãŒä¸æ˜ç­ |

**è¨ˆç®—å¼:** $s(i) = \\dfrac{b(i) - a(i)}{\\max(a(i),\\ b(i))}$

- $a(i)$: åŒä¸€ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®ä»–ã®ç‚¹ã¨ã®å¹³å‡è·é›¢ï¼ˆå‡é›†åº¦ï¼‰
- $b(i)$: æœ€ã‚‚è¿‘ã„ä»–ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‚¹ã¨ã®å¹³å‡è·é›¢ï¼ˆåˆ†é›¢åº¦ï¼‰
                    """
                )

            # Add cluster labels to dataframe
            result_df = data_subset.copy()
            result_df["ã‚¯ãƒ©ã‚¹ã‚¿"] = clusters

            # Cluster statistics
            st.markdown("### ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥çµ±è¨ˆ")
            cluster_stats = result_df.groupby("ã‚¯ãƒ©ã‚¹ã‚¿")[selected_cols].agg(["mean", "count"])
            cluster_stats.columns = [f"{col}_{agg}" for col, agg in cluster_stats.columns]
            st.dataframe(cluster_stats.reset_index(), use_container_width=True)

            # Visualization (2D)
            if len(selected_cols) >= 2:
                st.markdown("### ã‚¯ãƒ©ã‚¹ã‚¿ã®å¯è¦–åŒ–")
                fig = px.scatter(
                    result_df,
                    x=selected_cols[0],
                    y=selected_cols[1],
                    color=result_df["ã‚¯ãƒ©ã‚¹ã‚¿"].astype(str),
                    title=f"{selected_cols[0]} vs {selected_cols[1]}",
                    labels={"color": "ã‚¯ãƒ©ã‚¹ã‚¿"}
                )

                # Add cluster centers
                if standardize:
                    centers = scaler.inverse_transform(kmeans.cluster_centers_)
                else:
                    centers = kmeans.cluster_centers_

                fig.add_trace(go.Scatter(
                    x=centers[:, 0],
                    y=centers[:, 1],
                    mode="markers",
                    marker=dict(size=15, color="red", symbol="x", line=dict(width=2)),
                    name="ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒ"
                ))

                st.plotly_chart(fig, use_container_width=True)

            # Download results
            csv = result_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="kmeans_results.csv",
                mime="text/csv"
            )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


def show_elbow_method(df: pd.DataFrame, selected_cols: list, standardize: bool):
    """Show elbow method for determining optimal number of clusters."""
    st.markdown("### ã‚¨ãƒ«ãƒœãƒ¼æ³•")

    data_subset = df[selected_cols].dropna()

    if standardize:
        scaler = StandardScaler()
        X = scaler.fit_transform(data_subset)
    else:
        X = data_subset.values

    # Calculate inertia for different K values
    K_range = range(2, min(11, len(data_subset)))
    inertias = []
    silhouette_scores = []

    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(X)
        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(X, kmeans.labels_))

    # Plot
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=list(K_range), y=inertias, mode="lines+markers", name="æ…£æ€§"))
    fig.update_layout(
        title="ã‚¨ãƒ«ãƒœãƒ¼æ³•: ã‚¯ãƒ©ã‚¹ã‚¿æ•° vs æ…£æ€§",
        xaxis_title="ã‚¯ãƒ©ã‚¹ã‚¿æ•°",
        yaxis_title="æ…£æ€§"
    )
    st.plotly_chart(fig, use_container_width=True)

    # Silhouette scores
    fig_sil = go.Figure()
    fig_sil.add_trace(go.Scatter(x=list(K_range), y=silhouette_scores, mode="lines+markers"))
    fig_sil.update_layout(
        title="ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢",
        xaxis_title="ã‚¯ãƒ©ã‚¹ã‚¿æ•°",
        yaxis_title="ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢"
    )
    st.plotly_chart(fig_sil, use_container_width=True)
