"""
Conjoint Analysis module (simplified implementation).
"""
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from sklearn.linear_model import LinearRegression


def show_conjoint_analysis(df: pd.DataFrame):
    """Display Conjoint Analysis interface."""
    st.subheader("ğŸ“Š ã‚³ãƒ³ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåˆ†æ")

    with st.expander("ğŸ“– ä¸€èˆ¬çš„ãªåˆ†ææ‰‹é †", expanded=False):
        st.markdown(
            """
### ã‚³ãƒ³ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåˆ†æã®åŸºæœ¬çš„ãªæµã‚Œ

**1. ç›®çš„ã®æ˜ç¢ºåŒ–**
- è£½å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã®æœ€é©ãªçµ„ã¿åˆã‚ã›ã®ç™ºè¦‹
- å„å±æ€§ï¼ˆæ©Ÿèƒ½ã€ä¾¡æ ¼ã€ãƒ‡ã‚¶ã‚¤ãƒ³ãªã©ï¼‰ã®é‡è¦åº¦æ¸¬å®š
- é¡§å®¢ã®é¸å¥½æ§‹é€ ã®ç†è§£
- æ–°è£½å“é–‹ç™ºã«ãŠã‘ã‚‹æ„æ€æ±ºå®šæ”¯æ´
- ä¾¡æ ¼è¨­å®šæˆ¦ç•¥ã®ç­–å®š

**2. èª¿æŸ»è¨­è¨ˆï¼ˆãƒ‡ãƒ¼ã‚¿åé›†å‰ï¼‰**
- **å±æ€§ã®é¸å®š**: è£½å“ã‚’ç‰¹å¾´ã¥ã‘ã‚‹è¦ç´ ï¼ˆ3-6å€‹ãŒé©åˆ‡ï¼‰
  - ä¾‹: ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ â†’ ãƒ–ãƒ©ãƒ³ãƒ‰ã€ä¾¡æ ¼ã€ç”»é¢ã‚µã‚¤ã‚ºã€ãƒãƒƒãƒ†ãƒªãƒ¼å®¹é‡
- **æ°´æº–ã®è¨­å®š**: å„å±æ€§ã®é¸æŠè‚¢ï¼ˆ2-4æ°´æº–ãŒé©åˆ‡ï¼‰
  - ä¾‹: ä¾¡æ ¼ â†’ 3ä¸‡å††ã€5ä¸‡å††ã€7ä¸‡å††ã€10ä¸‡å††
- **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ**: å±æ€§ã®çµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³
  - å®Œå…¨è¦å› è¨ˆç”»ï¼ˆå…¨çµ„ã¿åˆã‚ã›ï¼‰ã¾ãŸã¯ç›´äº¤è¨ˆç”»ï¼ˆä¸€éƒ¨æŠ½å‡ºï¼‰
- **è©•ä¾¡æ–¹æ³•ã®æ±ºå®š**:
  - é †ä½æ³•: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †ä½ä»˜ã‘
  - è©•å®šæ³•: å„ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‚¹æ•°è©•ä¾¡ï¼ˆ1-10ç‚¹ãªã©ï¼‰
  - é¸æŠå‹: è¤‡æ•°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰1ã¤é¸æŠ

**3. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**
- **ç·åˆè©•ä¾¡åˆ—**: å›ç­”è€…ã®è©•ä¾¡ã‚¹ã‚³ã‚¢ï¼ˆæ•°å€¤å‹ï¼‰
- **å±æ€§åˆ—**: å„ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å±æ€§å€¤
  - æ•°å€¤å‹: ä¾¡æ ¼ã€ã‚µã‚¤ã‚ºãªã©
  - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å‹: ãƒ–ãƒ©ãƒ³ãƒ‰ã€è‰²ãªã©ï¼ˆãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã•ã‚Œã‚‹ï¼‰
- æ¬ æå€¤ã®å‡¦ç†
- å›ç­”è€…ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª

**4. åˆ†æã®å®Ÿè¡Œ**
- ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã§éƒ¨åˆ†åŠ¹ç”¨å€¤ã‚’æ¨å®š
- å±æ€§ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®å ´åˆï¼‰
- å„å±æ€§æ°´æº–ã®åŠ¹ç”¨å€¤ã‚’ç®—å‡º

**5. çµæœã®è§£é‡ˆ**
- **éƒ¨åˆ†åŠ¹ç”¨å€¤ï¼ˆPart-worth utilitiesï¼‰**:
  - å„å±æ€§æ°´æº–ãŒç·åˆè©•ä¾¡ã«ä¸ãˆã‚‹å½±éŸ¿åº¦
  - æ­£ã®å€¤: è©•ä¾¡ã‚’ä¸Šã’ã‚‹ã€è² ã®å€¤: è©•ä¾¡ã‚’ä¸‹ã’ã‚‹
  - çµ¶å¯¾å€¤ãŒå¤§ãã„ã»ã©å½±éŸ¿ãŒå¤§ãã„
- **ç›¸å¯¾çš„é‡è¦åº¦ï¼ˆRelative importanceï¼‰**:
  - å„å±æ€§ãŒæ„æ€æ±ºå®šã«å ã‚ã‚‹é‡è¦æ€§ã®å‰²åˆï¼ˆ%ï¼‰
  - åˆè¨ˆ100%ã«ãªã‚‹
  - æœ€ã‚‚é‡è¦ãªå±æ€§ã‚’ç‰¹å®š

**6. æ´»ç”¨æ–¹æ³•**
- **æœ€é©è£½å“ã®è¨­è¨ˆ**: åŠ¹ç”¨å€¤ãŒæœ€å¤§ã«ãªã‚‹çµ„ã¿åˆã‚ã›ã‚’é¸æŠ
- **å¸‚å ´ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ç«¶åˆè£½å“ã¨ã®æ¯”è¼ƒ
- **ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³**: é¡§å®¢å±¤ã”ã¨ã®é¸å¥½ã®é•ã„ã‚’åˆ†æ
- **ä¾¡æ ¼æˆ¦ç•¥**: ä¾¡æ ¼å¼¾åŠ›æ€§ã®æ¸¬å®š
- **What-ifåˆ†æ**: å±æ€§å¤‰æ›´ã®å½±éŸ¿äºˆæ¸¬

**7. æ³¨æ„ç‚¹**
- ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯å±æ€§Ã—æ°´æº–æ•°ã®3å€ä»¥ä¸ŠãŒæœ›ã¾ã—ã„
- å±æ€§ãŒå¤šã™ãã‚‹ã¨å›ç­”è€…ã®è² æ‹…ãŒå¤§ãã„ï¼ˆç–²åŠ´åŠ¹æœï¼‰
- éç¾å®Ÿçš„ãªçµ„ã¿åˆã‚ã›ã¯é™¤å¤–ã™ã‚‹
- äº¤äº’ä½œç”¨åŠ¹æœã¯è€ƒæ…®ã•ã‚Œãªã„ï¼ˆåŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼‰
            """
        )

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    all_cols = df.columns.tolist()

    if len(numeric_cols) < 2:
        st.warning("ã‚³ãƒ³ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåˆ†æã«ã¯æ•°å€¤å‹ã®è©•ä¾¡åˆ—ã¨å±æ€§åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        return

    preference_col = st.selectbox("ç·åˆè©•ä¾¡ï¼ˆç›®çš„å¤‰æ•°ï¼‰", numeric_cols)
    attribute_cols = st.multiselect(
        "å±æ€§ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰",
        [c for c in all_cols if c != preference_col],
        help="è£½å“ã®å±æ€§ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )

    if len(attribute_cols) < 1:
        st.info("å°‘ãªãã¨ã‚‚1ã¤ã®å±æ€§ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    if st.button("ã‚³ãƒ³ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåˆ†æã‚’å®Ÿè¡Œ", type="primary"):
        try:
            # Prepare data
            data_subset = df[[preference_col] + attribute_cols].dropna()

            # Handle categorical variables with one-hot encoding
            X = pd.get_dummies(data_subset[attribute_cols], drop_first=True)
            y = data_subset[preference_col]

            # Fit linear regression model
            model = LinearRegression()
            model.fit(X, y)

            st.success("ã‚³ãƒ³ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

            # Part-worth utilities
            st.markdown("### éƒ¨åˆ†åŠ¹ç”¨å€¤ï¼ˆPart-worth utilitiesï¼‰")

            # Parse attribute names and levels from dummy variable names
            utility_list = []
            for col, coef in zip(X.columns, model.coef_):
                # Try to split by underscore to separate attribute and level
                parts = col.split("_", 1)
                if len(parts) == 2:
                    attr_name, level = parts
                else:
                    # If no underscore, treat the whole column as both attribute and level
                    attr_name = col
                    level = col
                utility_list.append({"å±æ€§": attr_name, "æ°´æº–": level, "åŠ¹ç”¨å€¤": coef})

            # Add reference levels (utility = 0) for each attribute
            # These are the levels that were dropped by drop_first=True
            original_data = data_subset[attribute_cols]
            for attr_col in attribute_cols:
                # Check if this attribute was one-hot encoded (categorical)
                if original_data[attr_col].dtype == 'object' or original_data[attr_col].dtype.name == 'category':
                    # Get the first level (reference level)
                    first_level = sorted(original_data[attr_col].unique())[0]
                    # Check if this reference level is not already in the list
                    attr_name = attr_col
                    if not any(u["å±æ€§"] == attr_name and u["æ°´æº–"] == first_level for u in utility_list):
                        utility_list.append({"å±æ€§": attr_name, "æ°´æº–": str(first_level), "åŠ¹ç”¨å€¤": 0.0})

            utilities_extended = pd.DataFrame(utility_list)

            # Display table with attribute and level information
            utilities_table = utilities_extended[["å±æ€§", "æ°´æº–", "åŠ¹ç”¨å€¤"]].sort_values("åŠ¹ç”¨å€¤", ascending=False).reset_index(drop=True)
            st.dataframe(utilities_table, width="stretch")

            # Visualize part-worth utilities as line chart
            st.markdown("### åŠ¹ç”¨å€¤ã‚°ãƒ©ãƒ•")
            st.caption("å„å±æ€§ã®æ°´æº–ã”ã¨ã®åŠ¹ç”¨å€¤ã‚’æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã—ã¾ã™ã€‚åŠ¹ç”¨å€¤ãŒé«˜ã„ã»ã©ã€ãã®æ°´æº–ãŒç·åˆè©•ä¾¡ã«æ­£ã®å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚")

            if len(utilities_extended) > 0:
                fig = go.Figure()

                # Create x-axis labels: "Attribute: Level"
                utilities_extended = utilities_extended.copy()
                utilities_extended["x_label"] = utilities_extended["å±æ€§"] + ": " + utilities_extended["æ°´æº–"]

                # Sort by attribute and level for consistent ordering
                utilities_extended = utilities_extended.sort_values(["å±æ€§", "æ°´æº–"])

                # Get all unique x labels
                all_x_labels = utilities_extended["x_label"].tolist()

                # For each attribute, create a line that connects only its levels
                for attr_name in utilities_extended["å±æ€§"].unique():
                    attr_data = utilities_extended[utilities_extended["å±æ€§"] == attr_name]

                    # Create arrays with None for positions that don't belong to this attribute
                    x_vals = []
                    y_vals = []
                    text_vals = []

                    for x_label in all_x_labels:
                        if x_label in attr_data["x_label"].values:
                            row = attr_data[attr_data["x_label"] == x_label].iloc[0]
                            x_vals.append(x_label)
                            y_vals.append(row["åŠ¹ç”¨å€¤"])
                            text_vals.append(f"{row['åŠ¹ç”¨å€¤']:.2f}")
                        else:
                            x_vals.append(x_label)
                            y_vals.append(None)
                            text_vals.append("")

                    fig.add_trace(go.Scatter(
                        x=x_vals,
                        y=y_vals,
                        mode="lines+markers+text",
                        name=attr_name,
                        text=text_vals,
                        textposition="top center",
                        line=dict(width=2),
                        marker=dict(size=8),
                        connectgaps=False  # Don't connect across None values
                    ))

                fig.update_layout(
                    title="éƒ¨åˆ†åŠ¹ç”¨å€¤ã‚°ãƒ©ãƒ•",
                    xaxis_title="å±æ€§ã¨æ°´æº–",
                    yaxis_title="åŠ¹ç”¨å€¤",
                    hovermode="closest",
                    showlegend=True,
                    height=500,
                    xaxis=dict(showgrid=True, gridcolor='lightgray'),
                    yaxis=dict(showgrid=True, gridcolor='lightgray', zeroline=True, zerolinecolor='black', zerolinewidth=1)
                )
                fig.update_xaxis(tickangle=-45)
                st.plotly_chart(fig, width="stretch")

                with st.expander("ğŸ“– åŠ¹ç”¨å€¤ã‚°ãƒ©ãƒ•ã®èª­ã¿æ–¹"):
                    st.markdown(
                        """
**ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹ï¼š**
- **Xè»¸**: å„å±æ€§ã¨ãã®æ°´æº–ï¼ˆä¾‹: CPU: Celeron, HDDå®¹é‡: 5GBï¼‰
- **Yè»¸**: éƒ¨åˆ†åŠ¹ç”¨å€¤ï¼ˆæ­£ã®å€¤ã¯è©•ä¾¡ã‚’ä¸Šã’ã‚‹ã€è² ã®å€¤ã¯è©•ä¾¡ã‚’ä¸‹ã’ã‚‹ï¼‰
- **æŠ˜ã‚Œç·š**: å„å±æ€§å†…ã§ã®æ°´æº–é–“ã®åŠ¹ç”¨å€¤ã®å¤‰åŒ–
- **ã‚¼ãƒ­ç·š**: åŠ¹ç”¨å€¤0ã®ãƒ©ã‚¤ãƒ³ï¼ˆã“ã‚Œã‚ˆã‚Šä¸Šã¯æ­£ã®å½±éŸ¿ã€ä¸‹ã¯è² ã®å½±éŸ¿ï¼‰

**è§£é‡ˆã®ãƒã‚¤ãƒ³ãƒˆï¼š**
- åŠ¹ç”¨å€¤ãŒé«˜ã„æ°´æº–ã»ã©ã€é¡§å®¢ã®è©•ä¾¡ã‚’é«˜ã‚ã‚‹
- åŒã˜å±æ€§å†…ã§åŠ¹ç”¨å€¤ã®å·®ãŒå¤§ãã„ã»ã©ã€ãã®å±æ€§ã®é¸æŠãŒé‡è¦
- æ•°å€¤å‹å±æ€§ï¼ˆä¾¡æ ¼ãªã©ï¼‰ã¯ä¿‚æ•°ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã€1å˜ä½ã‚ãŸã‚Šã®åŠ¹ç”¨å¤‰åŒ–ã‚’ç¤ºã™
                        """
                    )

            # Relative importance
            st.markdown("### ç›¸å¯¾çš„é‡è¦åº¦")
            # Calculate the range (max - min) of utility values for each attribute
            importance_list = []
            for attr_name in utilities_extended["å±æ€§"].unique():
                attr_utilities = utilities_extended[utilities_extended["å±æ€§"] == attr_name]["åŠ¹ç”¨å€¤"]
                utility_range = attr_utilities.max() - attr_utilities.min()
                importance_list.append({"å±æ€§": attr_name, "ç¯„å›²": utility_range})

            importance_df = pd.DataFrame(importance_list)
            total_range = importance_df["ç¯„å›²"].sum()
            importance_df["é‡è¦åº¦(%)"] = (importance_df["ç¯„å›²"] / total_range * 100).round(2)
            importance_df = importance_df[["å±æ€§", "é‡è¦åº¦(%)"]].sort_values("é‡è¦åº¦(%)", ascending=False)

            col_table, col_chart = st.columns([1, 1])
            with col_table:
                st.dataframe(importance_df, width="stretch")
            with col_chart:
                fig_importance = go.Figure(go.Bar(
                    x=importance_df["é‡è¦åº¦(%)"],
                    y=importance_df["å±æ€§"],
                    orientation='h',
                    marker=dict(color=importance_df["é‡è¦åº¦(%)"], colorscale='Blues', showscale=False),
                    text=importance_df["é‡è¦åº¦(%)"].apply(lambda x: f"{x:.1f}%"),
                    textposition='outside'
                ))
                fig_importance.update_layout(
                    title="ç›¸å¯¾çš„é‡è¦åº¦",
                    xaxis_title="é‡è¦åº¦(%)",
                    yaxis_title="",
                    height=max(300, len(importance_df) * 50),
                    yaxis=dict(categoryorder='total ascending')
                )
                st.plotly_chart(fig_importance, width="stretch")

            # Model fit
            r2 = model.score(X, y)
            with st.container(border=True):
                st.metric("æ±ºå®šä¿‚æ•° (RÂ²)", f"{r2:.4f}")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
